Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Traceback (most recent call last):
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/bin/g2t-server-text", line 33, in <module>
    sys.exit(load_entry_point('graph2tac==0.1.0', 'console_scripts', 'g2t-server-text')())
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 248, in main
    tokenizer, model = load_eval_setup(tokenizer_location, model_location)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 86, in load_eval_setup
    model = model.to(device)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/transformers/modeling_utils.py", line 1878, in to
    return super().to(*args, **kwargs)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1126, in to
    device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)
RuntimeError: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu
Traceback (most recent call last):
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/bin/g2t-server-text", line 33, in <module>
    sys.exit(load_entry_point('graph2tac==0.1.0', 'console_scripts', 'g2t-server-text')())
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 248, in main
    tokenizer, model = load_eval_setup(tokenizer_location, model_location)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 86, in load_eval_setup
    model = model.to(device)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/transformers/modeling_utils.py", line 1878, in to
    return super().to(*args, **kwargs)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1126, in to
    device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)
RuntimeError: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu
Traceback (most recent call last):
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/bin/g2t-server-text", line 33, in <module>
    sys.exit(load_entry_point('graph2tac==0.1.0', 'console_scripts', 'g2t-server-text')())
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 248, in main
    tokenizer, model = load_eval_setup(tokenizer_location, model_location)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 86, in load_eval_setup
    model = model.to(device)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/transformers/modeling_utils.py", line 1878, in to
    return super().to(*args, **kwargs)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1126, in to
    device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)
RuntimeError: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu
Traceback (most recent call last):
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/bin/g2t-server-text", line 33, in <module>
    sys.exit(load_entry_point('graph2tac==0.1.0', 'console_scripts', 'g2t-server-text')())
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 248, in main
    tokenizer, model = load_eval_setup(tokenizer_location, model_location)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 86, in load_eval_setup
    model = model.to(device)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/transformers/modeling_utils.py", line 1878, in to
    return super().to(*args, **kwargs)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1126, in to
    device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)
RuntimeError: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu
Traceback (most recent call last):
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/bin/g2t-server-text", line 33, in <module>
    sys.exit(load_entry_point('graph2tac==0.1.0', 'console_scripts', 'g2t-server-text')())
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 248, in main
    tokenizer, model = load_eval_setup(tokenizer_location, model_location)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 86, in load_eval_setup
    model = model.to(device)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/transformers/modeling_utils.py", line 1878, in to
    return super().to(*args, **kwargs)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1126, in to
    device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)
RuntimeError: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu
Traceback (most recent call last):
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/bin/g2t-server-text", line 33, in <module>
    sys.exit(load_entry_point('graph2tac==0.1.0', 'console_scripts', 'g2t-server-text')())
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 248, in main
    tokenizer, model = load_eval_setup(tokenizer_location, model_location)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 86, in load_eval_setup
    model = model.to(device)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/transformers/modeling_utils.py", line 1878, in to
    return super().to(*args, **kwargs)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1126, in to
    device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)
RuntimeError: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu
Traceback (most recent call last):
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/bin/g2t-server-text", line 33, in <module>
    sys.exit(load_entry_point('graph2tac==0.1.0', 'console_scripts', 'g2t-server-text')())
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 248, in main
    tokenizer, model = load_eval_setup(tokenizer_location, model_location)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 86, in load_eval_setup
    model = model.to(device)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/transformers/modeling_utils.py", line 1878, in to
    return super().to(*args, **kwargs)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1126, in to
    device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)
RuntimeError: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu
Traceback (most recent call last):
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/bin/g2t-server-text", line 33, in <module>
    sys.exit(load_entry_point('graph2tac==0.1.0', 'console_scripts', 'g2t-server-text')())
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 248, in main
    tokenizer, model = load_eval_setup(tokenizer_location, model_location)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 86, in load_eval_setup
    model = model.to(device)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/transformers/modeling_utils.py", line 1878, in to
    return super().to(*args, **kwargs)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1126, in to
    device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)
RuntimeError: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu
Traceback (most recent call last):
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/bin/g2t-server-text", line 33, in <module>
    sys.exit(load_entry_point('graph2tac==0.1.0', 'console_scripts', 'g2t-server-text')())
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 248, in main
    tokenizer, model = load_eval_setup(tokenizer_location, model_location)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 86, in load_eval_setup
    model = model.to(device)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/transformers/modeling_utils.py", line 1878, in to
    return super().to(*args, **kwargs)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1126, in to
    device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)
RuntimeError: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu
Traceback (most recent call last):
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/bin/g2t-server-text", line 33, in <module>
    sys.exit(load_entry_point('graph2tac==0.1.0', 'console_scripts', 'g2t-server-text')())
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 248, in main
    tokenizer, model = load_eval_setup(tokenizer_location, model_location)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 86, in load_eval_setup
    model = model.to(device)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/transformers/modeling_utils.py", line 1878, in to
    return super().to(*args, **kwargs)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1126, in to
    device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)
RuntimeError: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu
File "./inversion.v", line 65, characters 0-7:
Error:
Anomaly "Uncaught exception Unix.Unix_error(Unix.EPIPE, "single_write", "")."
Please report at http://coq.inria.fr/bugs/.

File "./contact.v", line 160, characters 0-7:
Error:
Anomaly "Uncaught exception Unix.Unix_error(Unix.EPIPE, "single_write", "")."
Please report at http://coq.inria.fr/bugs/.

File "./equations_cercles.v", line 48, characters 0-8:
Error:
Anomaly "Uncaught exception Unix.Unix_error(Unix.EPIPE, "single_write", "")."
Please report at http://coq.inria.fr/bugs/.

File "./exercice_morley.v", line 121, characters 0-7:
Error:
Anomaly "Uncaught exception Unix.Unix_error(Unix.EPIPE, "single_write", "")."
Please report at http://coq.inria.fr/bugs/.

File "./applications_cocyclicite.v", line 380, characters 0-7:
Error:
Anomaly "Uncaught exception Unix.Unix_error(Unix.EPIPE, "single_write", "")."
Please report at http://coq.inria.fr/bugs/.

File "./homoth_Euler.v", line 193, characters 0-7:
Error:
Anomaly "Uncaught exception Unix.Unix_error(Unix.EPIPE, "single_write", "")."
Please report at http://coq.inria.fr/bugs/.

File "./transformations_contact.v", line 358, characters 0-8:
Error:
Anomaly "Uncaught exception Unix.Unix_error(Unix.EPIPE, "single_write", "")."
Please report at http://coq.inria.fr/bugs/.

File "./orientation.v", line 195, characters 0-34:
Error:
Anomaly "Uncaught exception Unix.Unix_error(Unix.EPIPE, "single_write", "")."
Please report at http://coq.inria.fr/bugs/.

File "./triangles_semblables.v", line 40, characters 0-24:
Error:
Anomaly "Uncaught exception Unix.Unix_error(Unix.EPIPE, "single_write", "")."
Please report at http://coq.inria.fr/bugs/.

File "./complexes_dilatations.v", line 415, characters 0-7:
Error:
Anomaly "Uncaught exception Unix.Unix_error(Unix.EPIPE, "single_write", "")."
Please report at http://coq.inria.fr/bugs/.

File "./exercice_morley.v", line 272, characters 0-7:
Error:
Anomaly "Uncaught exception Unix.Unix_error(Unix.EPIPE, "single_write", "")."
Please report at http://coq.inria.fr/bugs/.

File "./transformations_contact.v", line 377, characters 0-7:
Error:
Anomaly "Uncaught exception Unix.Unix_error(Unix.EPIPE, "single_write", "")."
Please report at http://coq.inria.fr/bugs/.

File "./contact.v", line 406, characters 0-8:
Error:
Anomaly "Uncaught exception Unix.Unix_error(Unix.EPIPE, "single_write", "")."
Please report at http://coq.inria.fr/bugs/.

File "./orientation.v", line 205, characters 0-34:
Error:
Anomaly "Uncaught exception Unix.Unix_error(Unix.EPIPE, "single_write", "")."
Please report at http://coq.inria.fr/bugs/.

Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
File "./applications_cocyclicite.v", line 477, characters 0-61:
Error:
Anomaly "Uncaught exception Unix.Unix_error(Unix.EPIPE, "single_write", "")."
Please report at http://coq.inria.fr/bugs/.

Traceback (most recent call last):
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/bin/g2t-server-text", line 33, in <module>
    sys.exit(load_entry_point('graph2tac==0.1.0', 'console_scripts', 'g2t-server-text')())
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 248, in main
    tokenizer, model = load_eval_setup(tokenizer_location, model_location)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 86, in load_eval_setup
    model = model.to(device)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/transformers/modeling_utils.py", line 1878, in to
    return super().to(*args, **kwargs)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1126, in to
    device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)
RuntimeError: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu
File "./triangles_semblables.v", line 49, characters 0-24:
Error:
Anomaly "Uncaught exception Unix.Unix_error(Unix.EPIPE, "single_write", "")."
Please report at http://coq.inria.fr/bugs/.

Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Traceback (most recent call last):
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/bin/g2t-server-text", line 33, in <module>
    sys.exit(load_entry_point('graph2tac==0.1.0', 'console_scripts', 'g2t-server-text')())
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 248, in main
    tokenizer, model = load_eval_setup(tokenizer_location, model_location)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 86, in load_eval_setup
    model = model.to(device)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/transformers/modeling_utils.py", line 1878, in to
    return super().to(*args, **kwargs)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1126, in to
    device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)
RuntimeError: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu
File "./complements_cercle.v", line 91, characters 0-7:
Error:
Anomaly "Uncaught exception Unix.Unix_error(Unix.EPIPE, "single_write", "")."
Please report at http://coq.inria.fr/bugs/.

File "./homothetie_plane.v", line 108, characters 0-7:
Error:
Anomaly "Uncaught exception Unix.Unix_error(Unix.EPIPE, "single_write", "")."
Please report at http://coq.inria.fr/bugs/.

Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Traceback (most recent call last):
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/bin/g2t-server-text", line 33, in <module>
    sys.exit(load_entry_point('graph2tac==0.1.0', 'console_scripts', 'g2t-server-text')())
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 248, in main
    tokenizer, model = load_eval_setup(tokenizer_location, model_location)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 86, in load_eval_setup
    model = model.to(device)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/transformers/modeling_utils.py", line 1878, in to
    return super().to(*args, **kwargs)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1126, in to
    device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)
RuntimeError: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Traceback (most recent call last):
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/bin/g2t-server-text", line 33, in <module>
    sys.exit(load_entry_point('graph2tac==0.1.0', 'console_scripts', 'g2t-server-text')())
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 248, in main
    tokenizer, model = load_eval_setup(tokenizer_location, model_location)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/graph2tac/transformer/pserver.py", line 86, in load_eval_setup
    model = model.to(device)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/transformers/modeling_utils.py", line 1878, in to
    return super().to(*args, **kwargs)
  File "/raid/scratch/piepejel/projects/coq-bench-15may/bd/target-source/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1126, in to
    device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)
RuntimeError: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu
File "./cocyclicite.v", line 252, characters 0-44:
Error:
Anomaly "Uncaught exception Unix.Unix_error(Unix.EPIPE, "single_write", "")."
Please report at http://coq.inria.fr/bugs/.

File "./reflexion_plane.v", line 725, characters 0-32:
Error:
Anomaly "Uncaught exception Unix.Unix_error(Unix.EPIPE, "single_write", "")."
Please report at http://coq.inria.fr/bugs/.

